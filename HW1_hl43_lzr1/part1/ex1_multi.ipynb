{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Homework 1: Part A2: Linear Regression with multiple variables\n",
    "## Experiments with the Boston housing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions \n",
    "This file contains code that helps you get started on linear regression with many variables. You will need to complete functions in **linear_regressor_multi.py** and **utils.py**. The only changes to make in this notebook are marked with **TODO**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data\n",
    "will start by loading and displaying some values from the full Boston housing dataset with thirteen features of census tracts that are believed to be predictive of the median home price in the tract (see **housing.names.txt** for a full description of these features). By looking at the values, you will note that the values of some of the features are  about 1000 times the values of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Reading data ...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.22489</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.377</td>\n",
       "      <td>94.3</td>\n",
       "      <td>6.3467</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>392.52</td>\n",
       "      <td>20.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11747</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.009</td>\n",
       "      <td>82.9</td>\n",
       "      <td>6.2267</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.09378</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.889</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.4509</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>390.50</td>\n",
       "      <td>15.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.62976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.949</td>\n",
       "      <td>61.8</td>\n",
       "      <td>4.7075</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.63796</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.096</td>\n",
       "      <td>84.5</td>\n",
       "      <td>4.4619</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.02</td>\n",
       "      <td>10.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.62739</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.834</td>\n",
       "      <td>56.5</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>395.62</td>\n",
       "      <td>8.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.05393</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.935</td>\n",
       "      <td>29.3</td>\n",
       "      <td>4.4986</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.85</td>\n",
       "      <td>6.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.78420</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.990</td>\n",
       "      <td>81.7</td>\n",
       "      <td>4.2579</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>386.75</td>\n",
       "      <td>14.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.72580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.727</td>\n",
       "      <td>69.5</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>390.95</td>\n",
       "      <td>11.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.57</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.85204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.965</td>\n",
       "      <td>89.2</td>\n",
       "      <td>4.0123</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>392.53</td>\n",
       "      <td>13.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.23247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.142</td>\n",
       "      <td>91.7</td>\n",
       "      <td>3.9769</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>18.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.54</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.75026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.924</td>\n",
       "      <td>94.1</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.33</td>\n",
       "      <td>16.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.84054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.599</td>\n",
       "      <td>85.7</td>\n",
       "      <td>4.4546</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>303.42</td>\n",
       "      <td>16.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.67191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>5.813</td>\n",
       "      <td>90.3</td>\n",
       "      <td>4.6820</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.88</td>\n",
       "      <td>14.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.95577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.047</td>\n",
       "      <td>88.8</td>\n",
       "      <td>4.4534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>306.38</td>\n",
       "      <td>17.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.77299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.495</td>\n",
       "      <td>94.4</td>\n",
       "      <td>4.4547</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>387.94</td>\n",
       "      <td>12.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.00245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.674</td>\n",
       "      <td>87.3</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.23</td>\n",
       "      <td>11.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.87141</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.484</td>\n",
       "      <td>93.6</td>\n",
       "      <td>2.3053</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.21</td>\n",
       "      <td>18.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>15.02340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>5.304</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.1007</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>349.48</td>\n",
       "      <td>24.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>10.23300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.185</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1705</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>379.70</td>\n",
       "      <td>18.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>14.33370</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.229</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.9512</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>383.32</td>\n",
       "      <td>13.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.82401</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.242</td>\n",
       "      <td>64.7</td>\n",
       "      <td>3.4242</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>10.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5.70818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>6.750</td>\n",
       "      <td>74.9</td>\n",
       "      <td>3.3317</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.07</td>\n",
       "      <td>7.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5.73116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>7.061</td>\n",
       "      <td>77.0</td>\n",
       "      <td>3.4106</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>395.28</td>\n",
       "      <td>7.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2.81838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.532</td>\n",
       "      <td>5.762</td>\n",
       "      <td>40.3</td>\n",
       "      <td>4.0983</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.92</td>\n",
       "      <td>10.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2.37857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.871</td>\n",
       "      <td>41.9</td>\n",
       "      <td>3.7240</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>370.73</td>\n",
       "      <td>13.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.67367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.312</td>\n",
       "      <td>51.9</td>\n",
       "      <td>3.9917</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.62</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5.69175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>6.114</td>\n",
       "      <td>79.8</td>\n",
       "      <td>3.5459</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>392.68</td>\n",
       "      <td>14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>4.83567</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583</td>\n",
       "      <td>5.905</td>\n",
       "      <td>53.2</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.22</td>\n",
       "      <td>11.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.15086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.454</td>\n",
       "      <td>92.7</td>\n",
       "      <td>1.8209</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>395.09</td>\n",
       "      <td>18.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.18337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.414</td>\n",
       "      <td>98.3</td>\n",
       "      <td>1.7554</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>344.05</td>\n",
       "      <td>23.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.20746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.093</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.8226</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>318.43</td>\n",
       "      <td>29.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.11132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>5.983</td>\n",
       "      <td>83.5</td>\n",
       "      <td>2.1099</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.27957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.926</td>\n",
       "      <td>42.6</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.17899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.670</td>\n",
       "      <td>28.8</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>393.29</td>\n",
       "      <td>17.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.28960</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.390</td>\n",
       "      <td>72.9</td>\n",
       "      <td>2.7986</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>21.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.26838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.794</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.8927</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.23912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.019</td>\n",
       "      <td>65.3</td>\n",
       "      <td>2.4091</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n",
       "0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n",
       "1     0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n",
       "2     0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n",
       "3     0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n",
       "4     0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n",
       "5     0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n",
       "6     0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n",
       "7     0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n",
       "8     0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n",
       "9     0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n",
       "10    0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n",
       "11    0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n",
       "12    0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n",
       "13    0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n",
       "14    0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n",
       "15    0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n",
       "16    1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n",
       "17    0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n",
       "18    0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n",
       "19    0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n",
       "20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n",
       "21    0.85204   0.0   8.14   0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n",
       "22    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n",
       "23    0.98843   0.0   8.14   0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n",
       "24    0.75026   0.0   8.14   0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n",
       "25    0.84054   0.0   8.14   0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n",
       "26    0.67191   0.0   8.14   0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n",
       "27    0.95577   0.0   8.14   0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n",
       "28    0.77299   0.0   8.14   0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n",
       "29    1.00245   0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n",
       "..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n",
       "476   4.87141   0.0  18.10   0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n",
       "477  15.02340   0.0  18.10   0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n",
       "478  10.23300   0.0  18.10   0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n",
       "479  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n",
       "480   5.82401   0.0  18.10   0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n",
       "481   5.70818   0.0  18.10   0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n",
       "482   5.73116   0.0  18.10   0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n",
       "483   2.81838   0.0  18.10   0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n",
       "484   2.37857   0.0  18.10   0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n",
       "485   3.67367   0.0  18.10   0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n",
       "486   5.69175   0.0  18.10   0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n",
       "487   4.83567   0.0  18.10   0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n",
       "488   0.15086   0.0  27.74   0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n",
       "489   0.18337   0.0  27.74   0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n",
       "490   0.20746   0.0  27.74   0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n",
       "491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n",
       "492   0.11132   0.0  27.74   0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n",
       "493   0.17331   0.0   9.69   0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n",
       "494   0.27957   0.0   9.69   0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n",
       "495   0.17899   0.0   9.69   0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n",
       "496   0.28960   0.0   9.69   0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n",
       "497   0.26838   0.0   9.69   0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n",
       "498   0.23912   0.0   9.69   0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n",
       "499   0.17783   0.0   9.69   0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n",
       "500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n",
       "501   0.06263   0.0  11.93   0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n",
       "502   0.04527   0.0  11.93   0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n",
       "503   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n",
       "504   0.10959   0.0  11.93   0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n",
       "505   0.04741   0.0  11.93   0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "5       18.7  394.12   5.21  \n",
       "6       15.2  395.60  12.43  \n",
       "7       15.2  396.90  19.15  \n",
       "8       15.2  386.63  29.93  \n",
       "9       15.2  386.71  17.10  \n",
       "10      15.2  392.52  20.45  \n",
       "11      15.2  396.90  13.27  \n",
       "12      15.2  390.50  15.71  \n",
       "13      21.0  396.90   8.26  \n",
       "14      21.0  380.02  10.26  \n",
       "15      21.0  395.62   8.47  \n",
       "16      21.0  386.85   6.58  \n",
       "17      21.0  386.75  14.67  \n",
       "18      21.0  288.99  11.69  \n",
       "19      21.0  390.95  11.28  \n",
       "20      21.0  376.57  21.02  \n",
       "21      21.0  392.53  13.83  \n",
       "22      21.0  396.90  18.72  \n",
       "23      21.0  394.54  19.88  \n",
       "24      21.0  394.33  16.30  \n",
       "25      21.0  303.42  16.51  \n",
       "26      21.0  376.88  14.81  \n",
       "27      21.0  306.38  17.28  \n",
       "28      21.0  387.94  12.80  \n",
       "29      21.0  380.23  11.98  \n",
       "..       ...     ...    ...  \n",
       "476     20.2  396.21  18.68  \n",
       "477     20.2  349.48  24.91  \n",
       "478     20.2  379.70  18.03  \n",
       "479     20.2  383.32  13.11  \n",
       "480     20.2  396.90  10.74  \n",
       "481     20.2  393.07   7.74  \n",
       "482     20.2  395.28   7.01  \n",
       "483     20.2  392.92  10.42  \n",
       "484     20.2  370.73  13.34  \n",
       "485     20.2  388.62  10.58  \n",
       "486     20.2  392.68  14.98  \n",
       "487     20.2  388.22  11.45  \n",
       "488     20.1  395.09  18.06  \n",
       "489     20.1  344.05  23.97  \n",
       "490     20.1  318.43  29.68  \n",
       "491     20.1  390.11  18.07  \n",
       "492     20.1  396.90  13.35  \n",
       "493     19.2  396.90  12.01  \n",
       "494     19.2  396.90  13.59  \n",
       "495     19.2  393.29  17.60  \n",
       "496     19.2  396.90  21.14  \n",
       "497     19.2  396.90  14.10  \n",
       "498     19.2  396.90  12.92  \n",
       "499     19.2  395.77  15.10  \n",
       "500     19.2  396.90  14.33  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plot_utils, utils\n",
    "from linear_regressor_multi import LinearRegressor_Multi, LinearReg_SquaredLoss\n",
    "\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "print 'Reading data ...'\n",
    "bdata = load_boston()\n",
    "df = pd.DataFrame(data = bdata.data, columns = bdata.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression with multiple variables\n",
    "When features differ by orders of magnitude, feature scaling becomes important\n",
    "to make  gradient descent converge  quickly.\n",
    "**Your task here is to complete the code in feature_normalize.py in utils.py**. \n",
    "- First, subtract the mean value of each feature from the dataset. \n",
    "- Second, divide the feature values by their respective standard deviations. The standard deviation is a way of measuring how much variation there is in the range of values of a particular feature (most data points will lie within two standard deviations of the mean).  \n",
    "\n",
    "You will do this for all the features and your code should work with\n",
    "datasets of all sizes (any number of features/examples). Note that each\n",
    "column of the matrix X corresponds to one feature.\n",
    "When normalizing the features, it is important\n",
    "to store the values used for normalization - the mean value and the standard deviation used for the computations.\n",
    "\n",
    "Then, run the computation in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.values\n",
    "y = bdata.target\n",
    "\n",
    "# need to scale the features (use zero mean scaling)\n",
    "\n",
    "X_norm,mu,sigma = utils.feature_normalize(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function and gradient descent (vectorized)\n",
    "Previously, you implemented gradient descent on a univariate regression problem. The only difference now is that there are more features in the matrix X. The hypothesis function and the batch gradient descent update\n",
    "rule remain unchanged. You should complete the code for the train method and the loss method at the indicated points\n",
    "in **linear_regressor_multi.py** to implement the cost function and gradient descent for linear regression with\n",
    "multiple variables.  Make sure your code supports any number of features and that it is **vectorized**.\n",
    "I recommend the use of  numpy's code vectorization facilities. You should see the cost $J(\\theta)$ converge as shown in Figure 5 of the assignment handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gradient descent ..\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHjCAYAAABme7hCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIpwBAIzI/wIZzbUIqKmu5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a17e4d190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed by gradient descent:  [  2.25328063e+01  -9.13925619e-01   1.06949712e+00   1.07531669e-01\n",
      "   6.87258582e-01  -2.05340341e+00   2.67719690e+00   1.55788957e-02\n",
      "  -3.10668099e+00   2.56946272e+00  -1.97453430e+00  -2.05873147e+00\n",
      "   8.55982884e-01  -3.74517559e+00]\n"
     ]
    }
   ],
   "source": [
    "# add intercept term to X_norm\n",
    "\n",
    "XX = np.vstack([np.ones((X.shape[0],)),X_norm.T]).T\n",
    "\n",
    "print 'Running gradient descent ..'\n",
    "\n",
    "# set up model and train \n",
    "\n",
    "linear_reg3 = LinearReg_SquaredLoss()\n",
    "J_history3 = linear_reg3.train(XX,y,learning_rate=0.01,num_iters=5000,verbose=False)\n",
    "\n",
    "# Plot the convergence graph and show it (or save it in fig5.pdf)\n",
    "\n",
    "plot_utils.plot_data(range(len(J_history3)),J_history3,'Number of iterations','Cost J')\n",
    "#plt.savefig(\"fig5.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Display the computed theta\n",
    "\n",
    "print 'Theta computed by gradient descent: ', linear_reg3.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict on unseen data points\n",
    "After learning the parameter $\\theta$, we  want to predict the median home prices for new census tracts. \n",
    "Given the thirteen characteristics x of a new census tract, we must first normalize x using the mean and standard deviations that we had previously computed from the training set. Then, we take the dot product of the normalized x (with a 1 prepended (to account for the intercept term) with the parameter vector $\\theta$ to make a prediction.\n",
    "In the cell below, your  final parameter values for $\\theta$ will  be used to make predictions on median home values\n",
    "for an average census tract, characterized by average values for all the thirteen features.  Complete the\n",
    "calculation in  the indicated lines below. Now run this cell to see what the  prediction of median home value for an average tract is. Remember to scale the features correctly for this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For average home in Boston suburbs, we predict a median home value of 225328.063241\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "# TODO:                                                                #\n",
    "# Predict values for the average home                                  #\n",
    "# remember to multiply prediction by 10000 using linear_reg3           #\n",
    "#   One line of code expected; replace pred_cost = 0 line              # \n",
    "########################################################################\n",
    "\n",
    "#X = one 1 and 13 0's\n",
    "#pred_cost = linear_reg3.predict(np.append(np.array([1]), np.zeros(X.shape[1]))) * 10000\n",
    "pred_cost = linear_reg3.predict(XX.mean(0)) * 10000\n",
    "print 'For average home in Boston suburbs, we predict a median home value of', pred_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal equations\n",
    "Using the closed form solution for $\\theta$ does not require any feature scaling, and you will get\n",
    "an exact solution in one calculation: there is no loop until convergence\n",
    "as in gradient descent.\n",
    "Complete the code in the method *normal_eqn* in *linear_regressor_multi.py* to  calculate $\\theta$. Now make a prediction for the average census tract (same example as in the previous problem). Do the predictions match up? Remember that while you do not need to scale your features, you still\n",
    "need to add a 1 to the example to have an intercept term ($\\theta_0$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed by direct solution is:  [  3.64911033e+01  -1.07170557e-01   4.63952195e-02   2.08602395e-02\n",
      "   2.68856140e+00  -1.77957587e+01   3.80475246e+00   7.51061703e-04\n",
      "  -1.47575880e+00   3.05655038e-01  -1.23293463e-02  -9.53463555e-01\n",
      "   9.39251272e-03  -5.25466633e-01]\n",
      "For average home in Boston suburbs, we predict a median home value of 225328.063241\n"
     ]
    }
   ],
   "source": [
    "X = df.values\n",
    "y = bdata.target\n",
    "XX1 = np.vstack([np.ones((X.shape[0],)),X.T]).T\n",
    "\n",
    "linear_reg4 = LinearReg_SquaredLoss()\n",
    "\n",
    "theta_n = linear_reg4.normal_equation(XX1,y)\n",
    "\n",
    "print 'Theta computed by direct solution is: ', theta_n\n",
    "\n",
    "########################################################################\n",
    "# TODO:                                                                #\n",
    "# Predict values for the average home using theta_n                    #\n",
    "# remember to multiply prediction by 10000                             #\n",
    "#   One line of code expected; replace pred_cost = 0 line              # \n",
    "########################################################################\n",
    "\n",
    "pred_cost = XX1.mean(0).dot(theta_n)  * 10000\n",
    "print 'For average home in Boston suburbs, we predict a median home value of', pred_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring convergence of gradient descent\n",
    "In this part of the exercise, you will get to try out different learning rates for\n",
    "the dataset and find a learning rate that converges quickly. You can change\n",
    "the learning rate and the number of iterations by modifying the call to the **LinearReg** constructor in the cell below.\n",
    "The next phase will call your train function and run gradient descent  at the chosen learning\n",
    "rate for the chosen number of iterations. The function should also return the history of $J(\\theta)$ values in a vector\n",
    "$J$. After the last iteration, the  script plots the $J$ values against\n",
    "the number of the iterations.\n",
    "If you picked a learning rate within a good range, your plot should look similar\n",
    "to Figure 5. If your graph looks very different, especially if your value of $J(\\theta)$\n",
    "increases or even blows up, adjust your learning rate and try again. We recommend trying values of the learning rate $\\alpha$ on a log-scale, at multiplicative\n",
    "steps of about 3 times the previous value (i.e., 0.3, 0.1, 0.03, 0.01 and so on).\n",
    "You may also want to adjust the number of iterations you are running if that\n",
    "will help you see the overall trend in the curve. Present plots of $J$ as a function of the number of iterations for different learning rates. What are good learning rates and number of iterations for this problem? Include plots and a brief writeup in **writeup.pdf** to justify your choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running gradient descent ..\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmcAAAHjCAYAAABme7hCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5P8Do8M+BfisgYcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a196ddbd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta computed by gradient descent:  [  2.25328063e+01  -9.13919321e-01   1.06948615e+00   1.07499392e-01\n",
      "   6.87263150e-01  -2.05339456e+00   2.67720344e+00   1.55734226e-02\n",
      "  -3.10668098e+00   2.56938115e+00  -1.97444289e+00  -2.05872778e+00\n",
      "   8.55982435e-01  -3.74517233e+00]\n"
     ]
    }
   ],
   "source": [
    "# change the learning_rate and num_iters in the call below to find the \n",
    "# best learning rate for this data set.\n",
    "\n",
    "learning_rates = [0.001,0.01, 0.03, 0.1, 0.3,0.33]\n",
    "\n",
    "########################################################################\n",
    "# TODO:                                                                #\n",
    "# Produce convergence plots for gradient descent with the rates above  #\n",
    "# using data (XX,y). Include them in your writeup.                     #\n",
    "#   4-5 lines of code expected                                         #\n",
    "########################################################################\n",
    "\n",
    "print 'Running gradient descent ..'\n",
    "\n",
    "# set up model and train \n",
    "\n",
    "linear_reg5 = LinearReg_SquaredLoss()\n",
    "J_history5 = linear_reg5.train(XX,y,learning_rate=learning_rates[-2],num_iters=200,verbose=False)\n",
    "\n",
    "# Plot the convergence graph and show it (or save it in fig5.pdf)\n",
    "\n",
    "plot_utils.plot_data(range(len(J_history5)),J_history5,'Number of iterations','Cost J')\n",
    "#plt.savefig(\"convergence_alpha_0.001_iter_50000.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Display the computed theta\n",
    "\n",
    "print 'Theta computed by gradient descent: ', linear_reg5.theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
