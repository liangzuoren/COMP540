{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  4.1\n",
      "Coefficients =  [-1.62837284] [[-0.01839052 -0.21661119  0.13128384  0.48674888  0.2602243   0.18532733\n",
      "   0.90344911  0.31288822  0.14199547  0.06198638 -0.05335911 -0.15162932\n",
      "  -0.0516569   0.02767041  0.23856918  0.76613529  0.46856035  0.08308522\n",
      "   0.26257561  0.22073129  0.26177729  0.41125323  0.7503693   0.26021176\n",
      "  -1.80207063 -0.62172528 -1.83095331 -0.11174736 -0.67814627 -0.16857307\n",
      "  -0.29711007 -0.20770702 -0.41815432 -0.42931161 -0.34816875  0.32415601\n",
      "   0.010483   -0.14344427 -0.3803836  -0.09968338 -0.63272648 -0.95488787\n",
      "  -0.32285734 -0.7132242  -0.79373552 -1.16416329 -0.133999   -0.67460068\n",
      "  -0.33001795 -0.15734097 -0.11687446  0.22802517  1.48301759  0.49456055\n",
      "  -0.12310253  0.83739199  0.38195683]]\n",
      "Accuracy on set aside test set for  std  =  0.921875\n",
      "best_lambda =  0.6\n",
      "Coefficients =  [-4.60944128] [[-0.45145759 -0.28466462 -0.06326929  0.68295889  1.21053267  0.91505182\n",
      "   2.83046514  1.43679096  0.24145529  0.35776707 -0.38644407 -0.48143415\n",
      "  -0.69587017  0.37456789  0.64885559  1.53956347  1.38117822  0.07197443\n",
      "   0.37642872  0.63502236  0.5227408   0.38563883  2.00139485  1.50816969\n",
      "  -3.14061245 -0.66616129 -4.90648744 -0.0325956  -1.28886415 -0.1574577\n",
      "  -0.6390073  -0.3023048  -1.00989869 -0.42569126 -1.08722214  1.28435133\n",
      "  -0.90558566 -0.35286054 -1.12971576 -0.62591321 -1.40337384 -2.44124209\n",
      "  -1.55654167 -1.94777881 -1.13114751 -2.79991602 -0.75122173 -2.11603146\n",
      "  -1.68511663 -0.66774001 -0.69125907  2.06912393  4.21977422  0.76308597\n",
      "   0.70345787  0.1700838   0.43018827]]\n",
      "Accuracy on set aside test set for  logt  =  0.943359375\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-1.82566817] [[ -1.78313887e-01  -1.60085507e-01  -3.73001110e-01   2.36358803e-01\n",
      "    9.46367589e-01   1.59613651e-01   2.03690641e+00   7.62617293e-01\n",
      "    1.81159712e-01   3.12388353e-01  -2.60352275e-01  -4.14115142e-01\n",
      "   -8.66097179e-01   2.36335389e-01   4.75358416e-01   1.43030139e+00\n",
      "    8.23118667e-01  -6.18540129e-02   2.39595774e-01   4.50237962e-01\n",
      "    7.24354333e-01   1.06352180e+00   8.70212070e-01   1.30340906e+00\n",
      "   -2.20348245e+00  -4.57176449e-01  -3.39242058e+00   5.45347538e-01\n",
      "   -5.60588208e-01  -1.85244388e-01  -8.05548612e-01  -4.84223732e-01\n",
      "   -6.36751902e-01  -8.68074821e-02  -6.31860076e-01   3.04485693e-01\n",
      "   -1.03756760e+00   4.18380737e-01  -7.08628404e-01  -2.18361508e-01\n",
      "   -1.07385026e+00  -1.74862153e+00  -6.95533233e-01  -1.43004581e+00\n",
      "   -7.40200633e-01  -2.11078936e+00  -9.46977028e-02  -1.24285032e+00\n",
      "   -2.91376073e-01   1.90460650e-01  -1.65731168e-01   1.19345678e+00\n",
      "    1.42337675e+00   6.04361398e-02   7.86190528e-04   7.86190528e-04\n",
      "    7.86190528e-04]]\n",
      "Accuracy on set aside test set for  bin  =  0.928385416667\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-13.80203121] [[ -5.55184746e-02  -1.99519351e-01   1.09810225e-01   2.78731245e+00\n",
      "    2.67965579e-01   2.65665058e-01   8.93723790e-01   2.98102253e-01\n",
      "    2.51624031e-01   6.80942297e-02  -6.81196646e-02  -1.52459409e-01\n",
      "   -3.60849760e-02   1.88336042e-02   1.60895370e-01   7.96650484e-01\n",
      "    5.50604675e-01   3.46012551e-02   2.69287572e-01   3.38210105e-01\n",
      "    2.50876748e-01   3.26461390e-01   6.95882937e-01   1.72589899e-01\n",
      "   -3.23351402e+00  -3.10730909e-01  -5.22156443e+01  -6.16108617e-02\n",
      "   -1.46977696e+00  -1.43363959e-02   1.95405817e-01   4.96710484e-01\n",
      "   -3.25079385e-01  -3.54425995e-01  -7.58678235e-01   4.30249419e-01\n",
      "    6.11640582e-02  -1.55698738e-01  -4.54439736e-01  -4.29959787e-02\n",
      "   -5.83614451e+00  -1.89034879e+00  -5.40869414e-01  -1.01150556e+00\n",
      "   -9.19007662e-01  -1.77247186e+00  -1.72131289e-01  -1.22823681e+00\n",
      "   -3.47632230e-01  -1.38059984e-01  -5.44362455e-02   1.97367758e-01\n",
      "    1.71530002e+00   1.08110026e+00   3.51497242e-01   2.64583807e+00\n",
      "    3.18238416e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.923828125\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-4.46310418] [[-0.34348725 -0.09562264  0.          0.12938317  1.18464571  0.69048283\n",
      "   2.91337137  1.37679007  0.          0.29511949  0.         -0.48055994\n",
      "  -0.32800392  0.10722066  0.          1.49528155  1.34899416  0.\n",
      "   0.35495638  0.19671539  0.49432879  0.34753838  1.78482954  1.3295319\n",
      "  -3.49783056 -0.26953896 -7.49422495  0.         -0.41743503  0.          0.\n",
      "   0.         -0.79151824  0.         -0.23868804  0.87183122 -0.77450643\n",
      "   0.         -0.88294261  0.         -0.30396021 -2.35510534 -0.69460828\n",
      "  -1.66140517 -1.1379025  -2.98253996  0.         -1.90099158 -1.24506271\n",
      "  -0.30338241  0.          2.01458854  5.36674389  0.          0.6368108\n",
      "   0.20189182  0.38809819]]\n",
      "Accuracy on set aside test set for  logt  =  0.944010416667\n",
      "best_lambda =  3.6\n",
      "Coefficients =  [-0.4683156] [[ 0.          0.         -0.19382951  0.          0.86593577  0.\n",
      "   2.02952581  0.63328221  0.02624344  0.21299905  0.         -0.42133359\n",
      "  -0.68116356  0.          0.          1.31527226  0.76594547  0.\n",
      "   0.10431087  0.12311694  0.63728686  0.73014232  0.62202065  1.18397849\n",
      "  -2.42342119 -0.12640986 -3.73148284  0.          0.          0.          0.\n",
      "   0.         -0.28818589  0.         -0.21919645  0.         -1.01542743\n",
      "   0.         -0.4052052   0.         -0.11573024 -1.69487091 -0.03897291\n",
      "  -1.11009226 -0.68721023 -2.21956213  0.         -1.02512235 -0.12500782\n",
      "   0.07412586  0.          1.15112188  1.49971477  0.         -0.64182383\n",
      "  -0.21236111 -0.34315221]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
