{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a KNN model for Kaggle Data Science Bowl 2018 - Quentin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 872 ms, sys: 166 ms, total: 1.04 s\n",
      "Wall time: 1.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 02/12/18\n",
    "import cv2\n",
    "import numpy as np\n",
    "import skimage\n",
    "import os\n",
    "\n",
    "train_sample_num = 10\n",
    "\n",
    "\n",
    "\n",
    "# import training set\n",
    "training_set = open('../input/stage1_train_labels.csv', 'r').readlines()\n",
    "\n",
    "# split the imageID and encodedPixels in the labels\n",
    "training_set_split = np.array([line[:-1].split(\",\") for line in training_set])\n",
    "\n",
    "# find all unique imageIDs (670 images)\n",
    "unique_imageIDs = np.unique(training_set_split[1:, 0])\n",
    "#print len(unique_imageIDs)\n",
    "\n",
    "\n",
    "#initialize X_train, y_train\n",
    "X_train = np.empty((0,4),int)\n",
    "y_train = np.empty((0),int)\n",
    "\n",
    "\n",
    "#load training data X_train, y_train\n",
    "for tain_im_ind in range(train_sample_num):\n",
    "#opencv uses BGR color format\n",
    "#imageID = \"00071198d059ba7f5914a526d124d28e6d010c92466da21d4a04cd5413362552\"\n",
    "\n",
    "    imageID = unique_imageIDs[tain_im_ind]\n",
    "    \n",
    "\n",
    "    #im_3 = cv2.imread(\"../\"+imageID+\"/images/\"+imageID+\".png\")\n",
    "    im_3 = cv2.imread(\"../input/stage1_train/\"+imageID+\"/images/\"+imageID+\".png\")\n",
    "    width = im_3.shape[0]\n",
    "    height = im_3.shape[1]\n",
    "    \n",
    "    #find BGR values and convert them into 1D vectors by concatenating columns\n",
    "    blue = im_3[:,:,0].flatten('F')\n",
    "    green = im_3[:,:,1].flatten('F')\n",
    "    red = im_3[:,:,2].flatten('F')\n",
    "    #convert to grayscale and find intensity\n",
    "    im_3_gray = cv2.cvtColor(im_3, cv2.COLOR_BGR2GRAY)\n",
    "    intensity = im_3_gray.flatten('F')\n",
    "    # create feature-based input data X. Four features are: blue, green, red, intensity\n",
    "    X_train_new = np.column_stack((blue, green, red, intensity))\n",
    "    #add the data from the new image to the previous X_train\n",
    "    X_train = np.vstack((X_train, X_train_new))\n",
    "    \n",
    "    y_train_new = np.zeros((width*height,))\n",
    "    # lines indices related to our sample image \n",
    "    line_ind = [ind for ind in range(len(training_set_split)) if training_set_split[ind][0] == imageID]\n",
    "    # complete mask of an image in format of pairs (start, run-length)\n",
    "    masks_pair = \" \".join([training_set_split[i][1] for i in line_ind])\n",
    "\n",
    "    # project the masks on y\n",
    "    mask1 = masks_pair.split()\n",
    "    mask2 = [int(item) for item in mask1]\n",
    "    mask3 = np.array(mask2)\n",
    "    mask4 = np.reshape(mask3, (len(mask3)/2, 2))\n",
    "    mask5 = [range(row[0],row[0]+row[1]) for row in mask4[:]]\n",
    "    import itertools\n",
    "    #find the complete mask of the image as an 1D array of indices (convert to Python indexing convention - start from 0)\n",
    "    mask_array = np.array(list(itertools.chain.from_iterable(mask5))) - np.array(1)\n",
    "    #print mask_array.shape\n",
    "    y_train_new[mask_array] = 255\n",
    "    \n",
    "    #add the data from the new image to the previous y_train\n",
    "    y_train = np.concatenate((y_train, y_train_new))\n",
    "\n",
    "# print X_train.shape\n",
    "# print y_train.shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 966 ms, total: 1min 10s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# train a KNN model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_sample_num = 65\n",
    "\n",
    "outfname = str(train_sample_num) + 'train' + str(test_sample_num) + 'test.txt'\n",
    "outf = open(outfname,'w')\n",
    "#write\n",
    "file_header = ('ImageId' + '\\t'+ 'EncodedPixels' + '\\n')\n",
    "outf.write(file_header)\n",
    "outf.flush()\n",
    "\n",
    "\n",
    "# load test set\n",
    "#test set directory\n",
    "test_dir = \"../input/stage1_test/\"\n",
    "#find all imageIDs in test set\n",
    "imageIDs_test = [name for name in os.listdir(test_dir) if os.path.isdir(test_dir+name)]\n",
    "\n",
    "#initialize X_test\n",
    "X_test = np.empty((0,4),int)\n",
    "\n",
    "\n",
    "for test_im_ind in range(test_sample_num):\n",
    "#opencv uses BGR color format\n",
    "#imageID = \"00071198d059ba7f5914a526d124d28e6d010c92466da21d4a04cd5413362552\"\n",
    "\n",
    "    imageID = imageIDs_test[test_im_ind]\n",
    "    \n",
    "    im_3 = cv2.imread(\"../input/stage1_test/\"+imageID+\"/images/\"+imageID+\".png\")\n",
    "    width = im_3.shape[0]\n",
    "    height = im_3.shape[1]\n",
    "    \n",
    "    \n",
    "    #find BGR values and convert them into 1D vectors by concatenating columns\n",
    "    blue = im_3[:,:,0].flatten('F')\n",
    "    green = im_3[:,:,1].flatten('F')\n",
    "    red = im_3[:,:,2].flatten('F')\n",
    "    #convert to grayscale and find intensity\n",
    "    im_3_gray = cv2.cvtColor(im_3, cv2.COLOR_BGR2GRAY)\n",
    "    intensity = im_3_gray.flatten('F')\n",
    "    # create feature-based input data X. Four features are: blue, green, red, intensity\n",
    "    X_test = np.column_stack((blue, green, red, intensity))\n",
    "    \n",
    "    # predict\n",
    "    y_pred = knn.predict(X_test) \n",
    "    # get the indices of pixels that belong to \"nuclei\" class. Convert indices to python convention\n",
    "    mask_pred = np.where(y_pred==255)[0] + np.array(1)\n",
    "    \n",
    "#     #temp\n",
    "#     print \"##############\"\n",
    "#     print imageID\n",
    "#     print width, height\n",
    "#     print len(y_pred)\n",
    "#     print \"##############\"\n",
    "    \n",
    "    \n",
    "    from script import PixelsToRLenc\n",
    "    #convert pixel array to a run-length string\n",
    "    mask_pred_rl = PixelsToRLenc(mask_pred)\n",
    "#     print mask_pred_rl\n",
    "#     print type(mask_pred_rl)\n",
    "    #mask_str = ' '.join(x for x in mask_pred_rl)\n",
    "    outf.write(imageID + '\\t' + mask_pred_rl + '\\n')\n",
    "    outf.flush()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "print \"mission complete\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
